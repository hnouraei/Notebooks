{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-parliament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T13:07:33.133884Z",
     "start_time": "2021-03-02T13:07:33.124102Z"
    }
   },
   "source": [
    "# Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-submission",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T16:35:55.437520Z",
     "start_time": "2021-03-04T16:35:55.416786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-remark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:57:19.925968Z",
     "start_time": "2021-03-03T14:57:19.917349Z"
    }
   },
   "source": [
    "## Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-palestinian",
   "metadata": {},
   "source": [
    "- df[[column1, column2]] the first bracket is for creating a list and the second one is syntax for a pandas dataframe \n",
    "\n",
    "- for a datetime object in pandas we should follow .dt.astimezone()\n",
    "- for a string formatting in pandas dataframe we should use .str.lower()\n",
    "- for filtering the categorical data, we should use .isin()\n",
    "\n",
    "---\n",
    "pd.ExcelFile() function\n",
    "\n",
    "workbook.sheet_names attribute\n",
    "\n",
    "workbook.parse() method\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-robinson",
   "metadata": {},
   "source": [
    "Remember: \n",
    "    \n",
    "-Remove dubplicate before you count by value_counts()\n",
    "\n",
    "-sort the index by .sort_index() before you slice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-satin",
   "metadata": {},
   "source": [
    "## Common pandas methods and attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proprietary-jackson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T13:08:43.054484Z",
     "start_time": "2021-03-02T13:08:43.044138Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    ".index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    ".columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    ".describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    ".head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    ".iloc, .loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    ".tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    ".info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    ".count(), .mean(), .std(), .median(), .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is used for categorical data \n",
    ".value_counts()\n",
    "# You can sort and normalize the counting numbers \n",
    ".value_counts(sort=True)\n",
    "\n",
    ".value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    ".values # convert the pandas data frame to numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['Name', 'Age']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# returns the type of each column in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype(int)\n",
    "# convert column type to int\n",
    "sales_df['Customer Number'] = sales_df['Customer Number'].astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-placement",
   "metadata": {},
   "source": [
    "## Drop a column in Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.drop ('MEDV', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-framing",
   "metadata": {},
   "source": [
    "## Sorting .sort_values(), .sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    ".sort_values()\n",
    "\n",
    "totals = totals.sort_values('revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    ".reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When inplace = True , the data is modified in place, which means it will \n",
    "#return nothing and the dataframe is now updated. When inplace = False , which is the default, \n",
    "#then the operation is performed and it returns a copy of the object. You then need to save\n",
    "#it to something.\n",
    ".sort_index(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi level index we must specifiy the keyword arguemnt 'level'\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level='city'))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=['country','city'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-topic",
   "metadata": {},
   "source": [
    "### Sorting by multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.sort_values([\"weight_kg\", \"height_cm\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-millennium",
   "metadata": {},
   "source": [
    "## Zooming or subsetting columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_subset = [\"breed\", \"height_cm\"] \n",
    "\n",
    "dogs[cols_to_subset]\n",
    "\n",
    "#or\n",
    "# The first bracket will create a list of column names and the second one will create the subset.\n",
    "cols_to_subset = [[\"breed\", \"height_cm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-error",
   "metadata": {},
   "source": [
    "### Subsetting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs[dogs[\"height_cm\"] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs[dogs[\"breed\"] == \"Labrador\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting based on multiple conditions\n",
    "is_lab = dogs[\"breed\"] == \"Labrador\"\n",
    "is_brown = dogs[\"color\"] == \"Brown\"\n",
    "\n",
    "dogs[is_lab & is_brown]\n",
    "dogs[is_lab | is_brown]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-third",
   "metadata": {},
   "source": [
    "#### Subsetting using .isin() for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_black_or_brown = dogs[\"color\"].isin([\"Black\", \"Brown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-bennett",
   "metadata": {},
   "source": [
    "## Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[fruit['name'] == \"Apple\"]\n",
    "fruit[fruit['price_usd'] > 1]\n",
    "fruit[fruit['price_usd'] > 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-software",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    ".mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis argument the default value for axis is \"index\". \n",
    "dogs_height_by_breed_vs_color.mean(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating summary stats across columns\n",
    "dogs_height_by_breed_vs_color.mean(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    ".median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    ".mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    ".min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    ".max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-level",
   "metadata": {},
   "outputs": [],
   "source": [
    ".var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    ".std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    ".sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    ".quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative statistics \n",
    ".cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    ".cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    ".cummmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    ".cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-diploma",
   "metadata": {},
   "source": [
    "### .agg() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-batch",
   "metadata": {},
   "source": [
    "DataFrame.agg(func=None, axis=0, *args, **kwargs)\n",
    "\n",
    "Aggregate using one or more operations over the specified axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct30(column):\n",
    "return column.quantile(0.3)\n",
    "\n",
    "dogs[\"weight_kg\"].agg(pct30)\n",
    "\n",
    "dogs[[\"weight_kg\", \"height_cm\"]].agg(pct30)\n",
    "\n",
    "dogs[\"weight_kg\"].agg([pct30, pct40])\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby('type')['weekly_sales'].agg([np.min,np.max, np.mean, np.median])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-dinner",
   "metadata": {},
   "source": [
    "### Dropping duplicate .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "vet_visits.drop_duplicates(subset=\"name\")\n",
    "\n",
    "unique_dogs = vet_visits.drop_duplicates(subset=[\"name\", \"breed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-basketball",
   "metadata": {},
   "source": [
    "### groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs[dogs[\"color\"] == \"Black\"][\"weight_kg\"].mean()\n",
    "dogs[dogs[\"color\"] == \"Brown\"][\"weight_kg\"].mean()\n",
    "dogs[dogs[\"color\"] == \"White\"][\"weight_kg\"].mean()\n",
    "dogs[dogs[\"color\"] == \"Gray\"][\"weight_kg\"].mean()\n",
    "dogs[dogs[\"color\"] == \"Tan\"][\"weight_kg\"].mean()\n",
    "\n",
    "# Instead of doing it like above we use groupby \n",
    "dogs.groupby(\"color\")[\"weight_kg\"].mean()\n",
    "\n",
    "dogs.groupby(\"color\")[\"weight_kg\"].agg([min, max, sum])\n",
    "\n",
    "# Grouping by multiple variables\n",
    "dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()\n",
    "# Many groups, many summaries \n",
    "dogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-sentence",
   "metadata": {},
   "source": [
    "## pivot_table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index is the column that we want to group by it. By default pivot table takes the mean value of the columns. \n",
    "# if we want to change the default function, we should you aggfunc keyword argument and numpy or custom functions.\n",
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\")\n",
    "\n",
    "# this is equivalent to following code without making the table \n",
    "dogs.groupby(\"color\")[\"weight_kg\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-chamber",
   "metadata": {},
   "source": [
    "### statistics in Pivot_table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple statistics \n",
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=[np.mean, np.median])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-stations",
   "metadata": {},
   "source": [
    "### Pivot on two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\")\n",
    "# NaN stands for missing values we can use fill_value keyword argument to replace missing values.\n",
    "\n",
    "# this is equlivalent to following code\n",
    "dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-making",
   "metadata": {},
   "source": [
    "### Filling missing values in pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-stuff",
   "metadata": {},
   "source": [
    "### Summing with pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# margins keyword will add the mean values of rows not including the missing values filled with 0\n",
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\", fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-hamilton",
   "metadata": {},
   "source": [
    "## Explicit indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-florida",
   "metadata": {},
   "source": [
    "## Setting a column as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ind = dogs.set_index(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-shore",
   "metadata": {},
   "source": [
    "## Removing an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to undo setting an index for pandas dataframe \n",
    "dogs_ind.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-accountability",
   "metadata": {},
   "source": [
    "### Dropping an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will remove the index that was set\n",
    "dogs_ind.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-landscape",
   "metadata": {},
   "source": [
    "### Multi-level indexes a.k.a. hierarchical indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ind3 = dogs.set_index([\"breed\", \"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-printing",
   "metadata": {},
   "source": [
    "#### Subset the outer level with a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ind3.loc[[\"Labrador\", \"Chihuahua\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-enclosure",
   "metadata": {},
   "source": [
    "#### Subset inner levels with a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ind3.loc[[(\"Labrador\", \"Brown\"), (\"Chihuahua\", \"Tan\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-medication",
   "metadata": {},
   "source": [
    "### Sorting by index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will sort all the indexes from outter to inner by ascending order we can all control the order by ascending keyword argumenet \n",
    "dogs_ind3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-housing",
   "metadata": {},
   "source": [
    "#### Controlling sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ind3.sort_index(level=[\"color\", \"breed\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-banks",
   "metadata": {},
   "source": [
    "## Slicing and subsetting with .loc[ ] and .iloc[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc[] and iloc[] are also a form of subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[23,2])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[:5,:])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:, 2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:5,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures['city'].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-headset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T16:59:20.205850Z",
     "start_time": "2021-03-04T16:59:20.194494Z"
    }
   },
   "source": [
    "### Slicing the outter index levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_srt.loc[\"Chow Chow\":\"Poodle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-tanzania",
   "metadata": {},
   "source": [
    "### Slicing the inner index levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember: inner index levels must always be used in Tuple format\n",
    "dogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-haiti",
   "metadata": {},
   "source": [
    "### Slicing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_srt.loc[:, \"name\":\"height_cm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-charlotte",
   "metadata": {},
   "source": [
    "### Slicing rows and columns at the sametime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\"),\"name\":\"height_cm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-slovakia",
   "metadata": {},
   "source": [
    "### Slicing by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dogs with date_of_birth between 2014-08-25 and 2016-09-16\n",
    "dogs.loc[\"2014-08-25\":\"2016-09-16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-socket",
   "metadata": {},
   "source": [
    "#### Slicing by partial dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dogs with date_of_birth between 2014-01-01 and 2016-12-31\n",
    "dogs.loc[\"2014\":\"2016\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-atlanta",
   "metadata": {},
   "source": [
    "### Subsetting by row/column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for .iloc() subsetting the last number is not included similar to list slicing. but for \n",
    "# .loc() method the names are included.\n",
    "print(dogs.iloc[2:5, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-dealing",
   "metadata": {},
   "source": [
    "## Visualizing your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "import matplotlib.pyplot as plt\n",
    "dog_pack[\"height_cm\"].hist()\n",
    "plt.show()\n",
    "\n",
    "dog_pack[\"height_cm\"].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "avg_weight_by_breed = dog_pack.groupby(\"breed\")[\"weight_kg\"].mean()\n",
    "print(avg_weight_by_breed)\n",
    "\n",
    "avg_weight_by_breed.plot(kind=\"bar\", title=\"Mean Weight by Dog Breed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line plots\n",
    "sully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\")\n",
    "plt.show()\n",
    "\n",
    "# Rotating axis labels\n",
    "sully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\", rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots\n",
    "dog_pack.plot(x=\"height_cm\", y=\"weight_kg\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layering plots\n",
    "dog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist()\n",
    "dog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist()\n",
    "plt.legend([\"F\", \"M\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transparency\n",
    "dog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist(alpha=0.7)\n",
    "dog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist(alpha=0.7)\n",
    "plt.legend([\"F\", \"M\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-thing",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-mixture",
   "metadata": {},
   "source": [
    "## Detecting missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it generates a boolean value for missing values. \n",
    "dogs.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-giant",
   "metadata": {},
   "source": [
    "## Detecting any missing values in columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-storage",
   "metadata": {},
   "source": [
    "## Counting missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.isna().sum()\n",
    "\n",
    "# Plotting missing values\n",
    "import matplotlib.pyplot as plt\n",
    "dogs.isna().sum().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-harrison",
   "metadata": {},
   "source": [
    "## Removing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One option is to remove the rows that contains the missing values\n",
    "dogs.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-client",
   "metadata": {},
   "source": [
    "## Replacing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one approach is to replace the missing values with zero. There are other methods available for replacing \n",
    "# missing values. \n",
    "dogs.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-sewing",
   "metadata": {},
   "source": [
    "# Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-pharmaceutical",
   "metadata": {},
   "source": [
    "## Creating a datafram by using Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hindu-richardson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T19:11:34.009692Z",
     "start_time": "2021-03-05T19:11:33.288271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name      breed  height_cm  weight_kg date_of_birth\n",
      "0  Ginger  Dachshund         22         10    2019-03-14\n",
      "1   Scout  Dalmatian         59         25    2019-05-09\n"
     ]
    }
   ],
   "source": [
    "# From a list of dictionaries Constructed row by row\n",
    "import pandas as pd\n",
    "list_of_dicts = [{\n",
    "    \"name\": \"Ginger\",\n",
    "    \"breed\": \"Dachshund\",\n",
    "    \"height_cm\": 22,\n",
    "    \"weight_kg\": 10,\n",
    "    \"date_of_birth\": \"2019-03-14\"\n",
    "}, {\n",
    "    \"name\": \"Scout\",\n",
    "    \"breed\": \"Dalmatian\",\n",
    "    \"height_cm\": 59,\n",
    "    \"weight_kg\": 25,\n",
    "    \"date_of_birth\": \"2019-05-09\"\n",
    "}]\n",
    "new_dogs = pd.DataFrame(list_of_dicts)\n",
    "print(new_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optical-participant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T19:13:02.129580Z",
     "start_time": "2021-03-05T19:13:02.121581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name      breed  height_cm  weight_kg date_of_birth\n",
      "0  Ginger  Dachshund         22         10    2019-03-14\n",
      "1   Scout  Dalmatian         59         25    2019-05-09\n"
     ]
    }
   ],
   "source": [
    "# From a dictionary of lists Constructed column by column\n",
    "dict_of_lists = {\n",
    "    \"name\": [\"Ginger\", \"Scout\"],\n",
    "    \"breed\": [\"Dachshund\", \"Dalmatian\"],\n",
    "    \"height_cm\": [22, 59],\n",
    "    \"weight_kg\": [10, 25],\n",
    "    \"date_of_birth\": [\"2019-03-14\", \"2019-05-09\"]\n",
    "}\n",
    "new_dogs = pd.DataFrame(dict_of_lists)\n",
    "print(new_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-contributor",
   "metadata": {},
   "source": [
    "# Reading and writing CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_dogs = pd.read_csv(\"new_dogs.csv\")\n",
    "print(new_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-enhancement",
   "metadata": {},
   "source": [
    "# Converting Pandas DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dogs.to_csv(\"new_dogs_with_bmi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-static",
   "metadata": {},
   "source": [
    "# Display image in markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "If you want to display the image in a Markdown cell then use:\n",
    "<img src=\"files/image.png\" width=\"800\" height=\"400\">\n",
    "If you want to display the image in a Code cell then use:\n",
    "from IPython.display import Image\n",
    "Image(filename='output1.png',width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-stability",
   "metadata": {},
   "source": [
    "# Pandas Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple pivot table in Python - .groupby().sum()\n",
    "\n",
    "fruit_sales.groupby('store', as_index=False).sum()\n",
    "\n",
    "fruit_sales.groupby(['store', 'product_name'], as_index=False).sum()\n",
    "\n",
    "groups = ['store', 'product_name']\n",
    "fruit_sales_less = fruit_sales.groupby(groups, as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table example \n",
    "\n",
    "# Raw data\n",
    "fruit_sales\n",
    "# Summary - by fruit by store\n",
    "totals = fruit_sales.groupby(['store', 'product_name'], as_index=False).sum()\n",
    "# Sort the Summary\n",
    "totals = (totals.sort_values('revenue', ascending=False)\n",
    ".reset_index(drop=True))\n",
    "# First row for each store\n",
    "top_store_sellers = totals.groupby('store').head(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with multiple sheets\n",
    "\n",
    "\n",
    "# Import package\n",
    "import pandas as pd\n",
    "# Read workbook\n",
    "fruit_workbook = pd.ExcelFile('fruit_tabs.xlsx')\n",
    "\n",
    "# Get sheet names\n",
    "fruit_sheet_names = fruit_workbook.sheet_names\n",
    "\n",
    "\n",
    "xls = pd.ExcelFile('path_to_file.xls')\n",
    "df1 = pd.read_excel(xls, 'Sheet1')\n",
    "df2 = pd.read_excel(xls, 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    ".parse() method\n",
    "# Read workbook\n",
    "fruit_workbook = pd.ExcelFile('fruit_tabs.xlsx')\n",
    "# Parse price tab\n",
    "fruit_prices = fruit_workbook.parse('price')\n",
    "\n",
    "# Print fruit prices\n",
    "print(fruit_prices)\n",
    "\n",
    "pd.ExcelFile() function\n",
    "workbook.sheet_names attribute \n",
    "workbook.parse() method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'weekday': ['Sun', 'Sun', 'Mon', 'Mon'],\n",
    "'city': ['Austin', 'Dallas', 'Austin', 'Dallas'],\n",
    "'visitors': [139, 237, 326, 456],\n",
    "'signups': [7, 12, 3, 5]}\n",
    "users = pd.DataFrame(data)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cities = ['Austin', 'Dallas', 'Austin', 'Dallas']\n",
    "signups = [7, 12, 3, 5]\n",
    "visitors = [139, 237, 326, 456]\n",
    "weekdays = ['Sun', 'Sun', 'Mon', 'Mon']\n",
    "list_labels = ['city', 'signups', 'visitors', 'weekday']\n",
    "list_cols = [cities, signups, visitors, weekdays]\n",
    "zipped = list(zip(list_labels, list_cols))\n",
    "\n",
    "data = dict(zipped)\n",
    "users = pd.DataFrame(data)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using na_values keyword\n",
    "sunspots = pd.read_csv(filepath, header=None, names=col_names, na_values={'sunspots':[' -1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parse_dates keyword\n",
    "sunspots = pd.read_csv(filepath, header=None, names=col_names, na_values={'sunspots':[' -1']}, parse_dates=[[0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dates as index\n",
    "sunspots.index = sunspots['year_month_day']\n",
    "sunspots.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing files\n",
    "out_csv = 'sunspots.csv'\n",
    "sunspots.to_csv(out_csv)\n",
    "out_tsv = 'sunspots.tsv'\n",
    "sunspots.to_csv(out_tsv, sep='\\t')\n",
    "out_xlsx = 'sunspots.xlsx'\n",
    "sunspots.to_excel(out_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsedate=True \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "aapl = pd.read_csv('aapl.csv', index_col='date',\n",
    "parse_dates=True)\n",
    "aapl.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_arr = aapl['close'].values\n",
    "type(close_arr)\n",
    "\n",
    "numpy.ndarray\n",
    "\n",
    "plt.plot(close_arr)\n",
    "[<matplotlib.lines.Line2D at 0x115550358>]\n",
    "plt.show()\n",
    "# plot array, series, data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert strings to datetime\n",
    "evening_2_11 = pd.to_datetime(['2015-2-11 20:00', '2015-2-11 21:00', '2015-2-11 22:00', '2015-2-11 23:00'])\n",
    "\n",
    "evening_2_11= DatetimeIndex(['2015-02-11 20:00:00', '2015-02-11 21:00:00','2015-02-11 22:00:00', '2015-02-11 23:00:00'],\n",
    "dtype='datetime64[ns]', freq=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing DataFrame\n",
    "sales.reindex(evening_2_11)\n",
    "\n",
    "Company Product Units\n",
    "2015-02-11 20:00:00 Initech Software 7.0\n",
    "2015-02-11 21:00:00 NaN NaN NaN\n",
    "2015-02-11 22:00:00 NaN NaN NaN\n",
    "2015-02-11 23:00:00 Hooli Software 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "sales.reindex(evening_2_11, method='ffill')\n",
    "Company Product Units\n",
    "2015-02-11 20:00:00 Initech Software 7\n",
    "2015-02-11 21:00:00 Initech Software 7\n",
    "2015-02-11 22:00:00 Initech Software 7\n",
    "2015-02-11 23:00:00 Hooli Software 4\n",
    "sales.reindex(evening_2_11, method='bfill')\n",
    "Company Product Units\n",
    "2015-02-11 20:00:00 Initech Software 7\n",
    "2015-02-11 21:00:00 Hooli Software 4\n",
    "2015-02-11 22:00:00 Hooli Software 4\n",
    "2015-02-11 23:00:00 Hooli Software 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling\n",
    "Statistical methods over different time intervals \n",
    " mean(), sum(), count()\n",
    "    \n",
    "#Downsampling \n",
    " reduce datetime rows to slower frequency\n",
    "    \n",
    "#Upsampling \n",
    " increase datatime rows to faster frequency \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-translator",
   "metadata": {},
   "source": [
    "| Input | Description | \n",
    "| :- | -: | \n",
    "| 'min' | 'T' minute |\n",
    "| 'H' | hour |\n",
    "| 'D' | day |\n",
    "| 'B' | business day |\n",
    "| 'W' | week |\n",
    "| 'M' | month |\n",
    "| 'Q' | quarter |\n",
    "| 'A' | year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating means\n",
    "daily_mean = sales.resample('D').mean()\n",
    "daily_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplying frequencies\n",
    "sales.loc[:,'Units'].resample('2W').sum()\n",
    "\n",
    "Date\n",
    "2015-02-08 82\n",
    "2015-02-22 79\n",
    "2015-03-08 14\n",
    "Freq: 2W-SUN, Name: Units, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "two_days = sales.loc['2015-2-4': '2015-2-5', 'Units']\n",
    "\n",
    "two_days\n",
    "Date\n",
    "2015-02-04 15:30:00 13\n",
    "2015-02-04 22:00:00 14\n",
    "2015-02-05 02:00:00 19\n",
    "2015-02-05 22:00:00 10\n",
    "Name: Units, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling and filling\n",
    "two_days.resample('4H').ffill()\n",
    "\n",
    "Date\n",
    "Date\n",
    "2015-02-04 12:00:00 NaN\n",
    "2015-02-04 16:00:00 13.0\n",
    "2015-02-04 20:00:00 13.0\n",
    "2015-02-05 00:00:00 14.0\n",
    "2015-02-05 04:00:00 19.0\n",
    "2015-02-05 08:00:00 19.0\n",
    "2015-02-05 12:00:00 19.0\n",
    "2015-02-05 16:00:00 19.0\n",
    "2015-02-05 20:00:00 19.0\n",
    "Freq: 4H, Name: Units, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String methods\n",
    "sales['Company'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substring matching\n",
    "sales['Product'].str.contains('ware')\n",
    "0 True\n",
    "1 True\n",
    "2 True\n",
    "3 True\n",
    "4 True\n",
    "5 True\n",
    "6 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean arithmetic\n",
    "True + False\n",
    "1\n",
    "True + True\n",
    "2\n",
    "False + False\n",
    "0\n",
    "\n",
    "Boolean reduction\n",
    "sales['Product'].str.contains('ware').sum()\n",
    "14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime methods\n",
    "sales['Date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timezone\n",
    "central = sales['Date'].dt.tz_localize('US/Central')\n",
    "central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timezone\n",
    "central.dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('world_population.csv', parse_dates=True, index_col= 'Date')\n",
    "\n",
    "population\n",
    "\n",
    "Population\n",
    "Date\n",
    "1960-12-31 2.087485e+10\n",
    "1970-12-31 2.536513e+10\n",
    "1980-12-31 3.057186e+10\n",
    "1990-12-31 3.644928e+10\n",
    "2000-12-31 4.228550e+10\n",
    "2010-12-31 4.802217e+10\n",
    "\n",
    "# Upsample population\n",
    "population.resample('A').first()\n",
    "\n",
    "Date\n",
    "1960-12-31 2.087485e+10\n",
    "1961-12-31 NaN\n",
    "1962-12-31 NaN\n",
    "1963-12-31 NaN\n",
    "1964-12-31 NaN\n",
    "1965-12-31 NaN\n",
    "1966-12-31 NaN\n",
    "1967-12-31 NaN\n",
    "1968-12-31 NaN\n",
    "1969-12-31 NaN\n",
    "1970-12-31 2.536513e+10\n",
    "1971-12-31 NaN\n",
    "1972-12-31 NaN\n",
    "\n",
    "# Interpolate missing data\n",
    "population.resample('A').first().interpolate('linear')\n",
    "Date\n",
    "1960-12-31 2.087485e+10\n",
    "1961-12-31 2.132388e+10\n",
    "1962-12-31 2.177290e+10\n",
    "1963-12-31 2.222193e+10\n",
    "1964-12-31 2.267096e+10\n",
    "1965-12-31 2.311999e+10\n",
    "1966-12-31 2.356902e+10\n",
    "1967-12-31 2.401805e+10\n",
    "1968-12-31 2.446707e+10\n",
    "1969-12-31 2.491610e+10\n",
    "1970-12-31 2.536513e+10\n",
    "1971-12-31 2.588580e+10\n",
    "1972-12-31 2.640648e+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.first\n",
    "DataFrame.first(offset)[source]\n",
    "Select initial periods of time series data based on a date offset.\n",
    "\n",
    "When having a DataFrame with dates as index, this function can select the first few rows based on a date offset.\n",
    "\n",
    "Parameters\n",
    "offsetstr, DateOffset or dateutil.relativedelta\n",
    "The offset length of the data that will be selected. For instance, ‘1M’ will display all the rows having their index within the first month.\n",
    "\n",
    "Returns\n",
    "Series or DataFrame\n",
    "A subset of the caller.\n",
    "\n",
    "Raises\n",
    "TypeError\n",
    "If the index is not a DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
    "ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
    "ts\n",
    "            A\n",
    "2018-04-09  1\n",
    "2018-04-11  2\n",
    "2018-04-13  3\n",
    "2018-04-15  4\n",
    "\n",
    "ts.first('3D')\n",
    "            A\n",
    "2018-04-09  1\n",
    "2018-04-11  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    ".merge()\n",
    "fruit_colors.merge(fruit_prices, on='name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "Concatenation basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat() along rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "Concatenating rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2, ...],\n",
    "ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating columns\n",
    "pd.concat([df1, df2, ...],\n",
    "axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = left_df.merge(right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "Three types of joins\n",
    "Types\n",
    "One-to-one\n",
    "One-to-many\n",
    "Many-to-many\n",
    "Join type indicates relationship of tables\n",
    "\n",
    "#Full syntax:\n",
    "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True,\n",
    "indicator=False, validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating merges\n",
    "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True,\n",
    "indicator=False, validate=None)\n",
    "Values for validate :\n",
    "“one_to_one” or “1:1”\n",
    "“one_to_many” or “1:m”\n",
    "“many_to_one” or “m:1”\n",
    "“many_to_many” or “m:m” (does nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-to-One Join \n",
    "pandas.merge()\n",
    "\n",
    "Left merges\n",
    "pd.merge(df_left, df_right, on='GameKey', how='left')\n",
    "\n",
    "Right merges\n",
    "pd.merge(df_left, df_right, on='GameKey', how='right')\n",
    "\n",
    "inner merges\n",
    "df1.merge(df2, left_on='GameKey', right_on='game-key',\n",
    "how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique key columns\n",
    "\n",
    "Unique values for single column key\n",
    "df.duplicated('GameKey').sum()\n",
    "\n",
    "df.duplicated(['GameKey', 'PlayId').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "Joining with .merge_ordered()\n",
    "\n",
    "pd.merge_ordered(cleveland, dallas, on='Game_Date',\n",
    "suffixes=['_CLE', '_DAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolating data\n",
    "pd.merge_ordered(tc2, td2, on='Game_Date', suffixes=['_CLE', '_DAL'], fill_method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging to nearest date-times\n",
    "\n",
    "pd.merge_asof(left_df, right_df, direction='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chapter 1 - Introduction to joining data\n",
    "Common situations\n",
    "Concatenate data by row or column\n",
    "pd.concat([df1, df2], axis=0)\n",
    "\n",
    "\n",
    "Chapter 2 - VLOOKUP-style joins\n",
    "One-to-one, VLOOKUP-style joins\n",
    "pd.merge(left_df, right_df,\n",
    "how='inner',\n",
    "on='key_column')\n",
    "\n",
    "Chapter 3- One-to-many joins\n",
    "Joins (merges) on key column\n",
    "df1.merge(df2, how='inner',\n",
    "on='key_column')\n",
    "Joins on unique index\n",
    "df1.join(df2, how='left')\n",
    "\n",
    "Chapter 4 - Advanced joins\n",
    "Advanced parameters\n",
    "left_index, right_index \n",
    "suffixes \n",
    "indicator \n",
    "sort \n",
    "pd.merge_ordered (left_df, right_df, how='outer')\n",
    "pd.merge_asof(left_df, right_df, direction='backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-syntax",
   "metadata": {},
   "source": [
    "# Efficient Pandas Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-nothing",
   "metadata": {},
   "source": [
    "## Pandas dataframe iteration\n",
    "\n",
    "Iterating with .iterrows() is much faster than .iloc() because it is similar to enumerate() for lists \n",
    "\n",
    "Iterating with .itertuples() is even faster than .iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row is a pandas data series that you can use column index to call out the cells\n",
    "for i,row in baseball_df.iterrows():\n",
    "    wins = row['W']\n",
    "    games_played = row['G']\n",
    "    win_perc = calc_win_perc(wins, games_played)\n",
    "    win_perc_list.append(win_perc)\n",
    "    \n",
    "baseball_df['WP'] = win_perc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_namedtuple in team_wins_df.itertuples():\n",
    "    print(row_namedtuple)\n",
    "    \n",
    "# output\n",
    "'''\n",
    "Pandas(Index=0, Team='ARI', Year=2012, W=81)\n",
    "Pandas(Index=1, Team='ATL', Year=2012, W=94)\n",
    "# The out put of .itertuples() is a espceial type of tuple called named tuple. it is just like tuple but\n",
    "the fields are accessible by attribute look up using . method. for example:\n",
    "\n",
    "print (row_namedtuple.Index)\n",
    "print (row_namedtuple.Team)\n",
    "print (row_namedtuple.Year)\n",
    "\n",
    "%%timeit\n",
    "for row_tuple in team_wins_df.iterrows():\n",
    "print(row_tuple)\n",
    "\n",
    "527 ms ± 41.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "vs.\n",
    "\n",
    "%%timeit\n",
    "for row_namedtuple in team_wins_df.itertuples():\n",
    "print(row_namedtuple)\n",
    "\n",
    "7.48 ms ± 243 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-builder",
   "metadata": {},
   "source": [
    "## pandas .apply() method\n",
    "\n",
    "Takes a function and applies it to a DataFrame. Must specify an axis to apply ( 0 for columns; 1 for rows)\n",
    "\n",
    "Can be used with anonymous functions ( lambda functions)\n",
    "\n",
    "Example:\n",
    "\n",
    "`def calc_run_diff(runs_scored, runs_allowed):\n",
    "    run_diff = runs_scored - runs_allowed\n",
    "    return run_diff`\n",
    "#### The lambda function act a map function, it takes a function and apply it to a data frame. \n",
    "\n",
    "Remember we have to specifiy the axis for the function to be applied. The argument for lambda is row.\n",
    "\n",
    "`baseball_df.apply(lambda row: calc_run_diff(row['RS'], row['RA']),axis=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-discrimination",
   "metadata": {},
   "source": [
    "## Power of vectorization \n",
    "\n",
    "### Broadcasting (vectorizing) is extremely efficient!\n",
    "\n",
    "The output is in a form of numpy array since the pandas was built on numpy arrays. The broadcasting approach is must faster than all other approaches. \n",
    "\n",
    "`wins_np = baseball_df['W'].values\n",
    " print(type(wins_np))`\n",
    " \n",
    " Example:\n",
    " \n",
    "`run_diffs_np = baseball_df['RS'].values - baseball_df['RA'].values\n",
    " baseball_df['RD'] = run_diffs_np\n",
    " print(baseball_df)`\n",
    " \n",
    " Example of all the three methods:\n",
    " \n",
    " `win_perc_preds_loop = []\n",
    "\n",
    "#Use a loop and .itertuples() to collect each row's predicted win percentage\n",
    "for row in baseball_df.itertuples():\n",
    "    runs_scored = row.RS\n",
    "    runs_allowed = row.RA\n",
    "    win_perc_pred = predict_win_perc(runs_scored, runs_allowed)\n",
    "    win_perc_preds_loop.append(win_perc_pred)\n",
    "\n",
    "#Apply predict_win_perc to each row of the DataFrame\n",
    "win_perc_preds_apply = baseball_df.apply(lambda row: predict_win_perc(row['RS'], row['RA']), axis=1)\n",
    "\n",
    "#Calculate the win percentage predictions using NumPy arrays\n",
    "win_perc_preds_np = predict_win_perc(baseball_df['RS'].values, baseball_df['RA'].values)\n",
    "baseball_df['WP_preds'] = win_perc_preds_np\n",
    "print(baseball_df.head())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-somerset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
